### 일일업무보고
- DW, DM 설계 완료(DM은 DS 변경사항 발생 시 변경 가능성 있음
- HDFS가 아닌 S3 클라우드 스토리지를 사용하는 방안 모색

### S3 사용 방안
- python - S3 - spark 형태로 연동
1. ubuntu 이미지에 spark를 hadoop을 따로 연동하지 않는 standalone 버전을 이용하여 설정
2. 여러 설정과 path를 잡고 s3 버킷을 생성하여 테스트 데이터를 넣어 spark 작동 확인
3. spark path가 잘못된 것인지 pyspark 모듈이 없다고 나옴
4. s3를 sparksession 이용하여 불러오는 코드까지 진행
5. path를 잡는다면 이대로 사용 가능해보임

- 오전 시작과 동시에 강사님 피드백 받고 결정

- 본래 환경 사용 가능성을 열어두고 docker push 해둔 상태
- git에 Airflow, Rest API, BI 관련 파일 추가 완료

- 필요시 본래 환경에서 바로 작업 시작 가능