# RDD Dependency(의존 관계)
- RDD에 복원성을 부여
- Spark Job 및 Task 생성에 영향

## RDD 의존 관계와 Spark 동작 메커니즘
- 스파크의 실행모델은 방향성 비순환 그래프 기반(DAG)
- Spark DAG
    - RDD를 정점으로 RDD **의존 관계**를 간선으로 정의한 그래프
    - RDD 계보
        - RDD의 변환 연산자를 호출할 때마다 새로운 정점(RDD)와 새로운 간선(의존 관계)이 생성된다
        - 변환 연산자로 생성된 새 RDD가 이전 RDD에 의존하므로 간선 방향은 **자식 RDD**(새 RDD)에서 **부모 RDD**(이전 RDD)로 향한다.
        - 이러한 RDD 의존 관계 그래프를 **RDD 계보**라고 한다.

### RDD 의존 관계
- 좁은(Narrow) 의존 관계
    - 셔플링이 발생하지 않는 변환 연산
    - 1 : 1 의존 관계
        - 셔플링이 필요하지 않은 모든 변환 연산자에 사용
    - 범위형(range) 의존 관계
        - 여러 부모 RDD에 대한 의존 관계를 하나로 결합한 경우로 union 변환 연산자만 해당
- 넓은(Wide)(또는 **셔플**) 의존 관계
    - 셔플링을 수행할 때 형성

## Spark의 Stage와 Task
- Spark는 셔플링이 발생하는 지점을 기준으로 Spark Job 하나를 여러 Stage로 나눈다.
- Spark는 각 Stage와 Partition 별로 Task를 생성해 실행자에 전달한다.
- Stage가 셔플링으로 끝나는 경우 이 단계의 Task를 **셔플-맵** Task라고 한다.
- Stage의 모든 태스크가 완료되면 드라이버는 다음 Stage의 Task를 생성하고 실행자에 전달한다.
    - 이 과정은 마지막 Stage 결과를 드라이버로 반환할 때까지 계속한다.
- 마지막 Stage에 생성된 Task를 결과 Task라고 한다.

## 체크포인트로 RDD 계보 저장
- 변환 연산자를 계속 이어 붙이면 RDD 계보가 제약 없이 길어질 수 있다.
- Spark는 전체 RDD를 안전한 스토리지에 보관할 수 있는 방법을 제공한다.
    - 일부 노드에 장애가 발생해도 유실된 RDD 조각을 처음부터 다시 계산할 필요가 없다.
- **체크포인팅** : Spark는 장애 발생 이전에 저장된 스냅샷을 사용해 이 지점부터 나머지 계보를 다시 계산한다.
    - 체크포인팅을 실행하면 스파크는 RDD의 모든 데이터를 디스크에 저장한다.
    - 스파크는 단순히 캐시처럼 RDD의 데이터만 저장하는 것이 아니라 RDD의 계보까지 모두 저장
    - 체크포인팅을 완료한 후에는 저장한 RDD를 다시 계산할 필요가 없으므로 해당 RDD 의존 관계와 부모 RDD 정보를 삭제
    - DAG가 길게 늘어진 RDD를 사용할 경우(RDD 의존 관계가 많은 경우) 노드에 장애가 발생핬을 때 유실된 데이터를 복구하는 데 오랜 시간이 걸릴 수 있다.
        - 이때, 체크포인트 파일에 저장해 둔 데이터를 읽어 들이는 것이 훨씬 더 빠를 수 있다.
        - 또한 Spark Streaming에도 중요한 역할을 한다.

## 누적 변수 공유 변수

### 누적 변수
- 여러 실행자가 공유하는 변수로 값을 더하는 연산만 허용
- 누적 변수를 사용해 스파크 잡의 전역 합계나 카운터를 구현할 수 있다.
- 누적 변수 값은 add 메서드나 += 연산자를 사용해 더한다.
- value 메서드로 변수 값을 가져올 수 있다.
- 그러나 누적 변수 값은 오직 드라이버만 참조할 수 있다.
    - 실행자가 누적 변수 값에 접근을 시도하면 예외 발생

### 공유 변수
- 여러 클러스터 노드가 공동으로 사용할 수 있는 변수
- 누적 변수와 달리 실행자가 수정할 수 없다.
- 드라이버만 공유 변수를 생성하며, 실행자에서는 읽기 연산만 가능

<br>

- 실행자 대다수가 대용량 데이터를 공통으로 사용할 때는 이 데이터를 공유 변수로 만드는 것이 좋다.
    - 변수를 필요 이상으로 여러 번 직렬화해 네트워크로 전송하는 상황이 발생할 수 있다.
    - 이때, 데이터를 더욱 최적화된 방식으로 단 한 번만 전송하는 공유 변수를 사용하는 편이 좋다.

<br>

- 공유 변수는 Broadcast 타입의 객체를 반환하는 SparkContext.broadcast(value) 메서드로 생성
    - value 인수에는 직렬화 가능한 모든 종류의 객체를 전달할 수 있다.
    - 공유 변수 값을 참조할 때는 항상 value 메서드를 사용해야 한다.
        - 그렇지 않으면 스파크는 이 변수를 자동으로 직렬화해 태스크와 함께 전송하기 때문에 공유 변수를 사용하는 이유, 성능상 이득을 잃어버린다.